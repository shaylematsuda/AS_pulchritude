---
title: "drc_fitting"
author: "Shayle Matsuda"
date: "2026-02-06"
output: html_document
editor_options: 
  chunk_output_type: console
---

---
title: "drc_fitting"
author: "ross"
date: "12/6/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(drc)
library(quantreg)
library(mcr)
library(broom)
library(lubridate)
library(janitor)
library(tidyverse)

# Create custom ggplot theme
theme_custom <- function() {
  theme_bw(base_size = 10, base_family = "Arial") %+replace%
    theme(
      panel.grid.major = element_blank(), 
      panel.grid.minor = element_blank(), 
      panel.background = element_blank(),
      panel.border = element_rect(color = "black", fill = NA),
      legend.background = element_rect(fill = NA, colour = NA),
      axis.title = element_text(size = 7),
      axis.text = element_text(size = 5)
    )
}

# # Labeller for treatments
# treatment_labeller <- function(variable, value){
#   return(list(
#   'Normal'="High light",
#   'lowLight'="Low light")[value])
# }
# 

# Function to pivot IPAM data to long form with column for AOI
ipam_convert <- function(data) {
  data %>% select_if(~ !any(is.na(.))) %>%
  pivot_longer(cols = starts_with("f") | starts_with("y")) %>%
  separate(name, into = c("var", "aoi"), sep = "(?<=[A-Za-z_])(?=[0-9])")
}
```

# Import rack, temperature, and coral position information
```{r}
# Import coral collection data
corals <- read_csv("data/raw_field_data/Collection_data.csv") %>%
  mutate(date = as_date(as.character(date_CBASS))) %>%
  filter(!is.na(date_CBASS))
corals <- corals %>%
  mutate(uniqueID = row_number()) #since no tag_no, creating a short unique ID for every genet

# Import CBASS metadata (positions of corals on racks, and CBASS temperatures of each rack)
rack_pos <- read_csv("data/raw_field_data/CBASS_rack_basket.csv") %>%
  mutate(date = as_date(as.character(date)))

rack_temp <- read_csv("data/raw_field_data/CBASS_rack_temp_map.csv", show_col_types = FALSE) %>%
  mutate(date = ymd(date)) %>%
  dplyr::select(1:4)



md <- full_join(rack_temp, rack_pos)

md <- md %>%
  unite(rack, rack_no, rack_config, sep = "")

```

# Import I-PAM data
```{r}
# Import PAM data
# List PAM files for pulchritude corals
pamfiles <- list.files(path = "data/IPAM_data", pattern = "*.csv", recursive = TRUE, full.names = TRUE)
pamfiles <- grep("Pulchritude", pamfiles, value = TRUE)

# Import data from each file
pam0 <- pamfiles %>%
  map_dfr(read_delim, delim = ";", .id = "file_id") %>%
  janitor::clean_names()

# Get date from name of directory of each PAM file (the date of each CBASS run), NOT the date/time in the .csv file, because the PAM laptop's clock was not necessarily set to the correct time zone.
pam1 <- pam0 %>%
  mutate(file_name = basename(pamfiles[as.numeric(file_id)]),
         date = as_date(str_extract(pamfiles[as.numeric(file_id)], "\\d{8}"), format = "%Y%m%d")) %>%
  dplyr::select(file_name, everything(), -file_id)

# # For files that have multiple sat pulses -- keep the last one only
pam1 <- pam1 %>%
  group_by(file_name, date) %>%
  filter(no == max(no)) %>%
  ungroup()

# For each source file, convert to long form data with F, FM, and YII for each AOI

pam1 <- pam1 %>%
  nest(data = -c(file_name, date)) %>%
  mutate(data2 = purrr::map(data, ipam_convert)) %>%
  unnest(data2) %>%
  dplyr::group_by(file_name, date) %>%
  dplyr::select(file_name, date, aoi, var, value) %>%
  ungroup()


pam1 <- pam1 %>%
  mutate(rack = str_remove(file_name, ".csv")) %>%
  dplyr::select(rack, everything(), -file_name)
  

# Join PAM data with rack order information (which PAM file corresponds to which rack of corals)
pam <- pam1 %>%
  group_by(rack, date) %>%
  mutate(position = ceiling(as.numeric(aoi)/2)) %>%
  ungroup()

pamf <- left_join(pam, md) %>% left_join(corals)

#write.csv(pamf,"pamf.csv")
# 
# 
# #2/12/26 same issue as RC code below had. 
# #Row 3649 of `x` matches multiple rows in `y`.
# left_join(pam, md) %>% slice(3649) #2026-01-22 basket NA??
# corals %>% filter(date == "2026-01-22", basket_no == NA) #does this mean metadata is bad on this date!!!!!
# 
# #Row 5 of `y` matches multiple rows in `x`.
# corals %>% slice(5)
# left_join(pam, md) %>% filter(date == "2026-01-20", basket_no == 15) %>% print(n = nrow(.))
# 
# ### ^^ need to reconcile these errors above. until then, omit these rows.
# 
# pamf1 <- pamf %>% filter(!(date == "2022-12-04" & basket_no == 20),
#                         !(date == "2022-12-10" & basket_no == 134))
# pamf2 <- filter(pamf1, !is.na(basket_no))

```

# Fit dose-response curves
```{r}
# Get Fv/Fm data and tidy
df <- pamf %>%
  #dplyr::select(rack, date_CBASS, tag_no, temp, aoi, position, var, value) %>%
  #filter(date_CBASS < 20240000) %>%
  mutate(max_temp = as.numeric(temp)) %>%
  pivot_wider(names_from =  var, values_from = value) %>%
  mutate(fvfmraw = y_ii_, fvfm = y_ii_) %>%
  dplyr::select(date, uniqueID, max_temp, f, fm, fvfmraw, fvfm)

ggplot(df, aes(x = max_temp, y = fvfm, color = factor(year(date)))) +
  geom_jitter()

#look at outlier IDs - ok they are all UniqueID 59, which is CBASS 1/22 Bag 71 (basket BAG71)
library(ggrepel)

ggplot(df, aes(x = max_temp, y = fvfm, color = factor(year(date)))) +
  geom_jitter(width = 0.15, height = 0) +
  geom_text_repel(aes(label = uniqueID),
                  size = 3,
                  max.overlaps = Inf)

# Define function to fit 3-parameter LL model to data and return NULL if fitting error
ll3 <- function(data) {
  drm(fvfm ~ max_temp, data = data, 
      fct = LL.3(names = c("hill", "max", "ED50")))}#,
      # upperl = c(50, 0.7, 40),
      # lowerl = c(20, 0.3, 30))}
tryll3 <- possibly(ll3, otherwise = NULL)

# Fit model to each coral, get parameters, fitted values, and residuals
initmods <- df %>%
  nest(data = c(max_temp, f, fm, fvfmraw, fvfm)) %>%
  # Fit the model to each coral
  mutate(ll3 = map(data, tryll3)) %>%
  # Get model parameters and fitted values/residuals
  mutate(pars = map(ll3, tidy),
         pred = map2(ll3, data, ~augment(.x, drop_na(.y, fvfm))))

# Extract ed50 parameter values from model fits
ed50 <- initmods %>% 
  dplyr::select(date, uniqueID, pars) %>%
  unnest(pars) %>%
  filter(term == "ED50")

ggplot(ed50, aes(x = estimate, fill = factor(year(date)))) +
  geom_histogram(position = "stack", alpha = 0.8, binwidth = 0.2) +
  theme_minimal()

ggplot(ed50, aes(x = factor(year(date)), y = estimate)) +
  geom_violin() +
  geom_jitter(width = 0.25)

#Collect raw data, fitted values, and diagnostics <- not running right creating duplicates 
vals <- initmods %>%
  select(date, uniqueID, pred) %>%
  unnest(pred) %>%
  full_join(ed50) %>%
  full_join(df) %>%
  rename(ed50 = estimate) %>%
  mutate(problem = "none")

countvals<-vals %>% count(uniqueID)
    #this is creating random duplicates of specific rows: 387 and 159. No idea why. 

dups <- vals %>%
  add_count(across(everything())) %>%   # count identical rows
  filter(n > 1) %>%                     # keep only duplicated rows
  select(-n)    #removing UniqueID 23 and 89 at 29C only ** not sure where this is happening **

dups
#Can't figure out where this is coming from. remove duplicate rows for now (2/19)
vals <- vals %>% distinct()




```

```{r drc_diagnostics}

# #### diagnostics
# Extract hill parameter values from model fits
# hill <- initmods %>%
#   select(nursery, uniqueID, pars) %>%
#   unnest(pars) %>%
#   filter(term == "hill")
# ggplot(hill) +
#   geom_histogram(aes(x = estimate))
# hill %>% arrange(estimate)
# 
# maxes <- initmods %>%
#   select(nursery, uniqueID, pars) %>%
#   unnest(pars) %>%
#   filter(term == "max")
# ggplot(maxes) +
#   geom_histogram(aes(x = estimate))
# maxes %>% arrange(-estimate)

# # Identify problematic data points based on cook's distance and residuals
counts <- vals %>%
  mutate(uniqueID = uniqueID) %>%
  group_by(uniqueID) %>%
  summarise(n = sum(!is.na(fvfm)))
dff <- vals %>%
  mutate(uniqueID = uniqueID) %>%
  left_join(counts) %>%
  group_by(uniqueID) %>%
  mutate(cooksd.thresh = 4/n) %>%   # Calculate cook's distance threshold as 4/n
  mutate(max_to_remove = floor(n * 0.2)) %>%
  ungroup() %>%
  mutate(problem = case_when(.cooksd > cooksd.thresh ~ "high cook's distance",
                             TRUE ~ "none")) %>%
  group_by(uniqueID, outlier = problem %in% c("high cook's distance", "high residual")) %>%
  mutate(n.outliers = n(),
         rank.out = order(.cooksd, decreasing = TRUE)) %>%
  ungroup() %>%
  mutate(fvfm = case_when(outlier & rank.out <= max_to_remove ~ .fitted,
                          TRUE ~ fvfm))

# Refit models without problematic points
fmods <- dff %>%
  select(uniqueID, max_temp, f, fm, fvfmraw, problem, fvfm) %>%
  nest(data = c(max_temp, f, fm, fvfmraw, fvfm, problem)) %>%
  # Fit the model to each coral
  mutate(ll3 = map(data, tryll3)) %>%
  # Get model parameters and fitted values/residuals
  mutate(pars = map(ll3, tidy),
         pred = map2(ll3, data, ~augment(.x, drop_na(.y, fvfm))))

# Extract ed50 parameter values from model fits
fed50 <- fmods %>%
  select(uniqueID, pars) %>%
  unnest(pars) %>%
  filter(term == "ED50")

#warnings....let's look #####
dff %>%
  group_by(uniqueID) %>%
  summarise(
    temp_min = min(max_temp),
    temp_max = max(max_temp),
    temp_range = temp_max - temp_min,
    fvfm_min = min(fvfm, na.rm = TRUE)
  ) %>%
  arrange(desc(temp_range))

bad_uniqueIDs <- fmods %>%
  select(uniqueID, pars) %>%
  unnest(pars) %>%
  filter(term == "ED50", is.nan(std.error) | is.na(std.error) | estimate > 50) %>%
  distinct(uniqueID) %>%
  pull(uniqueID)

bad_uniqueIDs
length(bad_uniqueIDs)

bad_uniqueIDs<-dff %>%
  filter(uniqueID %in% bad_uniqueIDs) %>%
  ggplot(aes(max_temp, fvfm)) +
  geom_point(alpha = 0.5) +
  facet_wrap(~uniqueID);bad_uniqueIDs



#####So some of these uniqueIDtypes do not have a sigmoidal curve, making model issues. We should figure out how to handle and also check on the species ID of these uniqueIDs. 

#temporarily, remove rows with the issues that are lower than 29 and higher than 38
fed50_filt <- fed50 %>%
  filter(is.finite(estimate), is.finite(std.error))
fed50_filt <- fed50_filt %>%
  filter(estimate >= 29, estimate <= 38) 

# Collect raw data, fitted values, and ed50 estimates
fvals <- fmods %>%
  select(uniqueID, pred) %>%
  unnest(pred) %>%
  full_join(fed50_filt) %>%
  full_join(select(dff, uniqueID, max_temp, f, fm, fvfmraw, problem, fvfm)) %>%
  rename(ed50 = estimate)
```


# Plot dose response curves for each uniqueIDtype
```{r plot, fig.width = 10, fig.height = 10}
ed50 <- ed50 %>%
  mutate(ID = factor(uniqueID))
ed50 <- ed50 %>%
  filter(estimate >= 29, estimate <= 38) 

fed50 <- fed50 %>%
  mutate(ID = factor(uniqueID))


vals <- vals %>%
  mutate(uniqueID = fct_reorder(factor(uniqueID), ed50, .fun = mean))
fvals <- vals %>%
  mutate(uniqueID = fct_reorder(factor(uniqueID), ed50, .fun = mean))


id_order <- fed50_filt %>%
  group_by(uniqueID) %>%
  summarise(estimate = first(estimate), .groups = "drop") %>%
  arrange(desc(estimate)) %>%
  pull(uniqueID)

vals <- vals %>%
  mutate(uniqueID = factor(as.character(uniqueID),
                           levels = as.character(id_order)))

ggplot(vals, aes(x = max_temp, y = fvfm)) +
  geom_point() +
  geom_line(aes(y = .fitted, group = uniqueID)) +
  geom_vline(aes(xintercept = estimate), data = fed50_filt, lty = 2) +
  geom_text(aes(x = estimate, y = 0.05, label = round(estimate, 2)),
            data = fed50_filt, size = 2, nudge_x = -1.5) +
  facet_wrap(~uniqueID) +
  coord_cartesian(xlim = c(26, 40)) #set these boundaries to filter out the outliers for now

hist(ed50$estimate, breaks = 30)
```
